# ğŸ OFF-Pipeline

Un sistema modular diseÃ±ado para consumir datos de la API de OpenFoodFacts (OFF), procesarlos y almacenarlos en PostgreSQL con capacidades de vectorizaciÃ³n preparadas para el futuro.

## ğŸ“‹ **Arquitectura General**

El proyecto estÃ¡ estructurado como un pipeline completo para el procesamiento de datos alimentarios, con mÃ³dulos especializados para cada etapa del proceso:

```
off-pipeline/
â”œâ”€â”€ off_client/         # Cliente para interactuar con la API de OFF
â”œâ”€â”€ storage/           # Modelos y conexiÃ³n a PostgreSQL
â”œâ”€â”€ scripts/           # Scripts de prueba y utilidades
â”œâ”€â”€ api/               # MÃ³dulo para API REST (preparado)
â”œâ”€â”€ data/              # Almacenamiento de datos (preparado)
â”œâ”€â”€ embedder/          # VectorizaciÃ³n de datos (preparado)
â”œâ”€â”€ preprocessor/      # Limpieza y procesamiento (preparado)
â””â”€â”€ docker-compose.yml # Infraestructura containerizada
```

## ğŸ”Œ **Cliente OpenFoodFacts**

### **Clase OFFClient** (`off_client/client.py`)

Cliente principal para interactuar con la API de OpenFoodFacts:

```python
class OFFClient:
    def __init__(self):
        user_agent = os.getenv("OFF_USER_AGENT")
        if not user_agent:
            raise RuntimeError("OFF_USER_AGENT no estÃ¡ definido en .env")
        self.api = openfoodfacts.API(user_agent=user_agent)

    def search_products(self, query: str, page_size: int = 20):
        """Busca productos que coincidan con `query` en OFF."""
        try:
            result = self.api.product.text_search(query)
            products = result.get("products", [])[:page_size]
            return products
        except requests.exceptions.ConnectionError:
            print("âŒ Error: No se pudo conectar a OpenFoodFacts.")
            return []
        except Exception as e:
            print(f"âŒ Error inesperado: {str(e)}")
            return []
```

### **CaracterÃ­sticas Clave:**

- **ğŸ” AutenticaciÃ³n:** Requiere obligatoriamente `OFF_USER_AGENT` en variables de entorno
- **ğŸ” BÃºsqueda por Texto:** Utiliza la API oficial de OpenFoodFacts
- **âš¡ Control de PaginaciÃ³n:** LÃ­mite configurable de resultados (default: 20)
- **ğŸ›¡ï¸ Manejo de Errores:** Control robusto de conectividad y errores inesperados
- **ğŸ“¦ LibrerÃ­a Oficial:** Usa `openfoodfacts>=0.1.7` (cliente oficial de Python)

## ğŸ’¾ **Sistema de Almacenamiento**

### **Modelos de Datos** (`storage/models.py`)

Estructura de datos optimizada para productos alimentarios:

```python
from sqlalchemy import Column, String, Float
from sqlalchemy.orm import DeclarativeBase

class Base(DeclarativeBase):
    pass

class Product(Base):
    __tablename__ = "products"
    code = Column(String, primary_key=True)        # CÃ³digo Ãºnico de OFF
    name = Column(String, nullable=False)          # Nombre del producto
    ingredients = Column(String)                   # Lista de ingredientes
    calories = Column(Float)                       # InformaciÃ³n nutricional
```

### **ConexiÃ³n PostgreSQL** (`storage/postgres.py`)

Gestor de persistencia con operaciones UPSERT:

```python
class PostgresStorage:
    def __init__(self):
        url = os.getenv("POSTGRES_URL")
        self.engine = create_engine(url)
        Base.metadata.create_all(self.engine)      # Auto-creaciÃ³n de tablas
        self.Session = sessionmaker(bind=self.engine)

    def upsert_product(self, product_data: dict):
        session = self.Session()
        obj = Product(**product_data)
        session.merge(obj)  # INSERT o UPDATE segÃºn la PK
        session.commit()
        session.close()
```

### **CaracterÃ­sticas del Storage:**

- **ğŸ”„ OperaciÃ³n Upsert:** `merge()` inserta nuevos productos o actualiza existentes
- **ğŸ—ï¸ Auto-setup:** Las tablas se crean automÃ¡ticamente si no existen
- **ğŸ”’ GestiÃ³n de Sesiones:** Apertura y cierre controlado de conexiones
- **ğŸ“Š Modelo Extensible:** Estructura preparada para mÃ¡s campos nutricionales

## ğŸ§ª **Scripts de Prueba**

### **1. Test Cliente OFF** (`scripts/test_off_client.py`)

```python
from off_client.client import OFFClient

client = OFFClient()
products = client.search_products("granola", page_size=5)

print("Productos encontrados:")
for p in products:
    name = p.get("product_name", "<sin nombre>")
    code = p.get("code", "<sin cÃ³digo>")
    print(f" - {name} (code: {code})")
```

### **2. Test ConexiÃ³n BD** (`scripts/test_db_connection.py`)

```python
import os
from dotenv import load_dotenv
from sqlalchemy import create_engine, text

load_dotenv()
url = os.getenv("POSTGRES_URL")
engine = create_engine(url)

with engine.connect() as conn:
    result = conn.execute(text("SELECT 1"))
    print("Postgres dice:", result.scalar())
```

### **3. Test InserciÃ³n** (`scripts/test_insert.py`)

```python
from storage.postgres import PostgresStorage

storage = PostgresStorage()
sample = {
    "code": "000000001",
    "name": "Granola Tutorial",
    "ingredients": "avena, nueces, pasas",
    "calories": 350.0
}

storage.upsert_product(sample)
print("Producto insertado/actualizado:", sample["code"])
```

## ğŸ³ **Infraestructura Docker**

### **Servicios Containerizados** (`docker-compose.yml`)

```yaml
version: '3.8'
services:
  postgres:
    image: postgres:14
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"

  weaviate:
    image: semitechnologies/weaviate:latest
    environment:
      - QUERY_DEFAULTS_LIMIT=20
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
    ports:
      - "8080:8080"
```

### **Servicios Incluidos:**

- **ğŸ˜ PostgreSQL 14:** Base de datos relacional principal
- **ğŸ” Weaviate:** Base de datos vectorial (preparada para embeddings futuros)
- **âš™ï¸ ConfiguraciÃ³n por Variables:** Todos los parÃ¡metros externalizados

## ğŸ“¦ **Dependencias**

### **LibrerÃ­as Principales** (`setup.py`)

```python
install_requires=[
    "sqlalchemy>=1.4.0",      # ORM para PostgreSQL
    "psycopg2-binary>=2.9.0", # Driver PostgreSQL
    "python-dotenv>=0.19.0",  # Variables de entorno
    "openfoodfacts>=0.1.7",   # Cliente oficial OFF
]
```

### **Stack TecnolÃ³gico:**

- **ğŸ Python 3.x:** Lenguaje principal
- **ğŸ—„ï¸ SQLAlchemy:** ORM para gestiÃ³n de base de datos
- **ğŸ”Œ OpenFoodFacts API:** Cliente oficial para consumir datos
- **ğŸ³ Docker:** ContainerizaciÃ³n de servicios
- **âš¡ PostgreSQL:** Base de datos relacional

## ğŸ”„ **Flujo de Trabajo Completo**

### **1. ConfiguraciÃ³n Inicial**

Crear archivo `.env` con las variables requeridas:

```env
# OpenFoodFacts API
OFF_USER_AGENT=tu-aplicacion-nombre/1.0

# PostgreSQL Configuration
POSTGRES_URL=postgresql://usuario:password@localhost:5432/off_db
POSTGRES_USER=usuario
POSTGRES_PASSWORD=password
POSTGRES_DB=off_db
```

### **2. Levantamiento de Servicios**

```bash
# Levantar infraestructura
docker-compose up -d

# Instalar dependencias
pip install -e .
```

### **3. Flujo de Procesamiento**

#### **Pasos Detallados:**

1. **ğŸ” InicializaciÃ³n:** Se crea instancia de `OFFClient` con validaciÃ³n de `user_agent`
2. **ğŸ” BÃºsqueda:** Se ejecuta `search_products()` con tÃ©rmino de bÃºsqueda especÃ­fico
3. **ğŸ“¥ ObtenciÃ³n de Datos:** La API devuelve JSON con productos filtrados
4. **ğŸ”„ TransformaciÃ³n:** Datos de OFF se mapean al modelo `Product` de SQLAlchemy
5. **ğŸ’¾ Persistencia:** `upsert_product()` guarda o actualiza productos en PostgreSQL

### **4. Ejemplo de Uso Completo**

```python
from off_client.client import OFFClient
from storage.postgres import PostgresStorage

# Inicializar servicios
client = OFFClient()
storage = PostgresStorage()

# Buscar productos
products = client.search_products("yogurt", page_size=10)

# Procesar y guardar cada producto
for product in products:
    product_data = {
        "code": product.get("code"),
        "name": product.get("product_name", "Sin nombre"),
        "ingredients": product.get("ingredients_text", ""),
        "calories": product.get("nutriments", {}).get("energy-kcal", 0.0)
    }
    
    storage.upsert_product(product_data)
    print(f"âœ… Producto guardado: {product_data['name']}")
```

## ğŸ›¡ï¸ **Manejo de Errores**

### **Niveles de ValidaciÃ³n:**

1. **ğŸ”’ Variables de Entorno:** ValidaciÃ³n obligatoria de `OFF_USER_AGENT` y `POSTGRES_URL`
2. **ğŸŒ Conectividad OFF:** Control especÃ­fico de `ConnectionError`
3. **ğŸ—„ï¸ Conectividad PostgreSQL:** ValidaciÃ³n de conexiÃ³n a base de datos
4. **ğŸ“Š Datos Inconsistentes:** Manejo graceful de campos faltantes en productos
5. **âš ï¸ Errores Generales:** Captura y logging de excepciones inesperadas

### **Estrategias de RecuperaciÃ³n:**

- **ğŸ”„ Reintentos AutomÃ¡ticos:** Para errores de conectividad temporal
- **ğŸ“ Logging Descriptivo:** Mensajes claros para debugging
- **ğŸš« Fallos Graceful:** El sistema continÃºa funcionando con datos parciales
- **ğŸ›¡ï¸ ValidaciÃ³n de Entrada:** VerificaciÃ³n de datos antes del procesamiento

## ğŸš€ **Estado Actual vs. Potencial Futuro**

### **âœ… Funcional Actualmente:**

- **ğŸ” Cliente OFF:** BÃºsqueda bÃ¡sica por texto en OpenFoodFacts
- **ğŸ’¾ Almacenamiento:** Persistencia completa en PostgreSQL
- **ğŸ§ª Testing:** Scripts de validaciÃ³n y pruebas unitarias
- **ğŸ›¡ï¸ Error Handling:** Manejo robusto de errores de conectividad
- **ğŸ³ ContainerizaciÃ³n:** Infraestructura lista para producciÃ³n

### **ğŸ“¦ Preparado para ExpansiÃ³n:**

- **ğŸ¤– Embedder Module:** VectorizaciÃ³n de ingredientes y descripciones
- **ğŸ§¹ Preprocessor Module:** Limpieza y normalizaciÃ³n de datos
- **ğŸ”— API REST:** Endpoints para consulta externa de productos
- **ğŸ“Š Data Analytics:** AnÃ¡lisis nutricional y tendencias alimentarias
- **ğŸ¯ Recomendaciones:** Sistema de recomendaciÃ³n basado en similitud

### **ğŸ”® Arquitectura Futura:**

```mermaid
graph TB
    A[OpenFoodFacts API] --> B[OFFClient]
    B --> C[Preprocessor]
    C --> D[PostgreSQL]
    C --> E[Embedder]
    E --> F[Weaviate Vector DB]
    D --> G[REST API]
    F --> G
    G --> H[Frontend/Analytics]
```

## ğŸš¦ **Comandos de Desarrollo**

### **Setup Inicial:**

```bash
# Clonar y configurar
git clone <repo>
cd off-pipeline

# Configurar entorno
cp .env.example .env  # Editar variables necesarias

# Levantar servicios
docker-compose up -d

# Instalar dependencias
pip install -e .
```

### **Testing:**

```bash
# Test conexiÃ³n OFF
python scripts/test_off_client.py

# Test conexiÃ³n PostgreSQL
python scripts/test_db_connection.py

# Test inserciÃ³n completa
python scripts/test_insert.py
```

### **Desarrollo:**

```bash
# Logs de servicios
docker-compose logs -f

# Reiniciar servicios
docker-compose restart

# Limpiar volÃºmenes
docker-compose down -v
```

## ğŸ¤ **Contribuir**

Este proyecto estÃ¡ diseÃ±ado con una arquitectura modular que facilita la extensiÃ³n y mejora continua. Las Ã¡reas de contribuciÃ³n incluyen:

- **ğŸ” Mejoras en Cliente OFF:** MÃ¡s mÃ©todos de bÃºsqueda y filtrado
- **ğŸ—„ï¸ ExtensiÃ³n de Modelos:** MÃ¡s campos nutricionales y metadata
- **ğŸ¤– ImplementaciÃ³n de Embedder:** Vector embeddings para similitud semÃ¡ntica
- **ğŸ§¹ Desarrollo de Preprocessor:** Limpieza y normalizaciÃ³n de datos
- **ğŸ”— API REST:** Endpoints para acceso externo
- **ğŸ“Š Analytics Dashboard:** VisualizaciÃ³n de datos nutricionales

---

**Este README proporciona una guÃ­a exhaustiva del funcionamiento actual del sistema OFF-Pipeline, desde la configuraciÃ³n inicial hasta el flujo completo de datos, incluyendo la arquitectura preparada para escalabilidad futura.**
